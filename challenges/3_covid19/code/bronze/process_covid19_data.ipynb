{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Configuração do ambiente de desenvolvimento para realização do ETL (Extract Transform Load)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instalando bibliotecas\n",
    "\n",
    "Instalando todas as bibliotecas necessárias e criação do ambiente spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/05/07 00:40:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark version:  3.5.4\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.master(\"local\").config(\"spark.executor.memory\", \"6g\") \\\n",
    "    .config(\"spark.driver.memory\", \"6g\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"6g\") \\\n",
    "    .appName(\"PySpark Tutorial\").getOrCreate()\n",
    "\n",
    "# Verify Spark version\n",
    "print(\"Spark version: \", spark.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre Processamento\n",
    "\n",
    "Uma vez que os arquivos bases são grandes, para evitar esforço computacional e consumo de disco desnecessário, Estamos reescrevendo os dados Bronze para parquet, com somente os meses necessários (Necessário rodar somente uma vez, para gerar `bronze.parquet`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/07 00:49:05 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 148, schema size: 145\n",
      "CSV file: file:///home/lucas-nunes/workspace/Postech/challenges/3_covid19/data/bronze/micro_data/ano_part=2020/mes=11/PNAD_COVID_112020.csv\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "INPUT_PATH = '/home/lucas-nunes/workspace/Postech/challenges/3_covid19/data/bronze/micro_data'\n",
    "INPUT_PATH_SAMPLE = '/home/lucas-nunes/workspace/Postech/challenges/3_covid19/input/data/micro_data/ano=2020/item=05/PNAD_COVID_052020.csv'\n",
    "\n",
    "SILVER_PATH = '/home/lucas-nunes/workspace/Postech/challenges/3_covid19/data/silver'\n",
    "BRONZE_PATH = '/home/lucas-nunes/workspace/Postech/challenges/3_covid19/data/bronze'\n",
    "\n",
    "df = spark.read.csv(INPUT_PATH, header=True)\n",
    "\n",
    "df = df.where(col('mes') >= 9)\n",
    "\n",
    "df.toPandas().to_parquet(f'{BRONZE_PATH}/bronze.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criação da estrutura dos valores\n",
    "\n",
    "Mapeamento dos campos que serão recebidos e atribuição do tipo primitivo de cada um, Normalização de todos as colunas, retirando acentuação e caracteres especiais, e definição dos campos de particionamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'StructType' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m schema_investing_fields \u001b[38;5;241m=\u001b[39m \u001b[43mStructType\u001b[49m([\n\u001b[1;32m      2\u001b[0m     StructField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData\u001b[39m\u001b[38;5;124m\"\u001b[39m, DateType(), \u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m      3\u001b[0m     StructField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mÚltimo\u001b[39m\u001b[38;5;124m\"\u001b[39m, FloatType(), \u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m      4\u001b[0m     StructField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAbertura\u001b[39m\u001b[38;5;124m\"\u001b[39m, FloatType(), \u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m      5\u001b[0m     StructField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMáxima\u001b[39m\u001b[38;5;124m\"\u001b[39m, FloatType(), \u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m      6\u001b[0m     StructField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMínima\u001b[39m\u001b[38;5;124m\"\u001b[39m, FloatType(), \u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m      7\u001b[0m     StructField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVol.\u001b[39m\u001b[38;5;124m\"\u001b[39m, StringType(), \u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m      8\u001b[0m     StructField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVar\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m, StringType(), \u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m      9\u001b[0m ])\n\u001b[1;32m     11\u001b[0m columns_to_float \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124multimo\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mabertura\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaxima\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminima\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     14\u001b[0m rename_fields \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mÚltimo\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124multimo\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVar\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvariacao\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     22\u001b[0m }\n",
      "\u001b[0;31mNameError\u001b[0m: name 'StructType' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "schema_investing_fields = StructType([\n",
    "    StructField(\"Data\", DateType(), True),\n",
    "    StructField(\"Último\", FloatType(), True),\n",
    "    StructField(\"Abertura\", FloatType(), True),\n",
    "    StructField(\"Máxima\", FloatType(), True),\n",
    "    StructField(\"Mínima\", FloatType(), True),\n",
    "    StructField(\"Vol.\", StringType(), True),\n",
    "    StructField(\"Var%\", StringType(), True),\n",
    "])\n",
    "\n",
    "columns_to_float = ['ultimo', 'abertura', 'maxima', 'minima']\n",
    "\n",
    "\n",
    "rename_fields = {\n",
    "    \"Data\": \"data\",\n",
    "    \"Último\": \"ultimo\",\n",
    "    \"Abertura\": \"abertura\",\n",
    "    \"Máxima\": \"maxima\",\n",
    "    \"Mínima\": \"minima\",\n",
    "    \"Vol.\": \"volume\",\n",
    "    \"Var%\": \"variacao\"\n",
    "}\n",
    "\n",
    "partitions = ['category', 'item']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mapeamento dos paths que irão ser utilizados para o tratamento dos dados e leitura dos arquivos utilizando particionamento spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_PATH = '/home/lucas-nunes/workspace/Postech/challenges/3_covid/data/bronze/micro_data/'\n",
    "INPUT_PATH_SAMPLE = '/home/lucas-nunes/workspace/Postech/challenges/3_covid/input/data/micro_data/ano=2020/item=cobre/Dados Históricos - Cobre Futuros.csv'\n",
    "\n",
    "SILVER_PATH = '/home/lucas-nunes/workspace/Postech/challenges/3_covid/data/silver'\n",
    "BRONZE_PATH = '/home/lucas-nunes/workspace/Postech/challenges/3_covid/data/bronze'\n",
    "\n",
    "# df = spark.read.csv(INPUT_PATH, header=True)\n",
    "df = pd.read_parquet(f'{BRONZE_PATH}/bronze.parquet')\n",
    "\n",
    "df = df.withColumnsRenamed(rename_fields)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/07 00:40:18 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gerando Bronze parquet para processamentos\n",
    "\n",
    "Uma vez que os arquivos bases são grandes, para evitar esforço computacional e consumo de disco desnecessário, Estamos reescrevendo os dados Bronze para parquet, com somente os meses necessários (Necessário rodar somente uma vez, para gerar `bronze.parquet`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.toPandas().to_csv(f'{SILVER_PATH}/silver.csv')\n",
    "df.toPandas().to_parquet(f'{BRONZE_PATH}/bronze.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.printSchema of DataFrame[Ano: string, UF: string, CAPITAL: string, RM_RIDE: string, V1008: string, V1012: string, V1013: string, V1016: string, Estrato: string, UPA: string, V1022: string, V1023: string, V1030: string, V1031: string, V1032: string, posest: string, A001: string, A001A: string, A001B1: string, A001B2: string, A001B3: string, A002: string, A003: string, A004: string, A005: string, A006: string, A007: string, A008: string, A009: string, B0011: string, B0012: string, B0013: string, B0014: string, B0015: string, B0016: string, B0017: string, B0018: string, B0019: string, B00110: string, B00111: string, B00112: string, B00113: string, B002: string, B0031: string, B0032: string, B0033: string, B0034: string, B0035: string, B0036: string, B0037: string, B0041: string, B0042: string, B0043: string, B0044: string, B0045: string, B0046: string, B005: string, B006: string, B007: string, B008: string, B009A: string, B009B: string, B009C: string, B009D: string, B009E: string, B009F: string, B0101: string, B0102: string, B0103: string, B0104: string, B0105: string, B0106: string, B011: string, C001: string, C002: string, C003: string, C004: string, C005: string, C0051: string, C0052: string, C0053: string, C006: string, C007: string, C007A: string, C007B: string, C007C: string, C007D: string, C007E: string, C007E1: string, C007E2: string, C007F: string, C008: string, C009: string, C009A: string, C010: string, C0101: string, C01011: string, C01012: string, C0102: string, C01021: string, C01022: string, C0103: string, C0104: string, C011A: string, C011A1: string, C011A11: string, C011A12: string, C011A2: string, C011A21: string, C011A22: string, C012: string, C013: string, C014: string, C015: string, C016: string, C017A: string, D0011: string, D0013: string, D0021: string, D0023: string, D0031: string, D0033: string, D0041: string, D0043: string, D0051: string, D0053: string, D0061: string, D0063: string, D0071: string, D0073: string, E001: string, E0021: string, E0022: string, E0023: string, E0024: string, F001: string, F0021: string, F0022: string, F002A1: string, F002A2: string, F002A3: string, F002A4: string, F002A5: string, F0061: string, F006: string, ano_part: int, mes: int]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.printSchema of DataFrame[Ano: string, UF: string, CAPITAL: string, RM_RIDE: string, V1008: string, V1012: string, V1013: string, V1016: string, Estrato: string, UPA: string, V1022: string, V1023: string, V1030: string, V1031: string, V1032: string, posest: string, A001: string, A001A: string, A001B1: string, A001B2: string, A001B3: string, A002: string, A003: string, A004: string, A005: string, A006: string, A007: string, A008: string, A009: string, B0011: string, B0012: string, B0013: string, B0014: string, B0015: string, B0016: string, B0017: string, B0018: string, B0019: string, B00110: string, B00111: string, B00112: string, B00113: string, B002: string, B0031: string, B0032: string, B0033: string, B0034: string, B0035: string, B0036: string, B0037: string, B0041: string, B0042: string, B0043: string, B0044: string, B0045: string, B0046: string, B005: string, B006: string, B007: string, B008: string, B009A: string, B009B: string, B009C: string, B009D: string, B009E: string, B009F: string, B0101: string, B0102: string, B0103: string, B0104: string, B0105: string, B0106: string, B011: string, C001: string, C002: string, C003: string, C004: string, C005: string, C0051: string, C0052: string, C0053: string, C006: string, C007: string, C007A: string, C007B: string, C007C: string, C007D: string, C007E: string, C007E1: string, C007E2: string, C007F: string, C008: string, C009: string, C009A: string, C010: string, C0101: string, C01011: string, C01012: string, C0102: string, C01021: string, C01022: string, C0103: string, C0104: string, C011A: string, C011A1: string, C011A11: string, C011A12: string, C011A2: string, C011A21: string, C011A22: string, C012: string, C013: string, C014: string, C015: string, C016: string, C017A: string, D0011: string, D0013: string, D0021: string, D0023: string, D0031: string, D0033: string, D0041: string, D0043: string, D0051: string, D0053: string, D0061: string, D0063: string, D0071: string, D0073: string, E001: string, E0021: string, E0022: string, E0023: string, E0024: string, F001: string, F0021: string, F0022: string, F002A1: string, F002A2: string, F002A3: string, F002A4: string, F002A5: string, F0061: string, F006: string, ano_part: int, mes: int]>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.printSchema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tratamento dos valores e colunas, remoção de caracteres especiais e abreviações de milhar \"K\" ou milhão \"M\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in columns_to_float:\n",
    "\n",
    "    df = df.withColumn(column, regexp_replace(regexp_replace(column, r'\\.', ''), ',', r'\\.').astype('float'))\n",
    "\n",
    "\n",
    "df = df.withColumn('variacao', regexp_replace(regexp_replace('variacao', r'%', ''), ',', r'\\.').astype('float'))\n",
    "df = df.withColumn('volume', regexp_replace(regexp_replace('volume', r'K', ''), ',', r'\\.').astype('float'))\n",
    "df = df.withColumn('data', to_date(col('data'), 'dd.MM.yyyy'))\n",
    "df = df.drop_duplicates(subset=['data', 'item'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escrevendo arquivo tratado pelo tier bronze, com todos os dados concatenados e tratados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/07 00:40:19 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "25/05/07 00:40:23 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 148, schema size: 145\n",
      "CSV file: file:///home/lucas-nunes/workspace/Postech/challenges/3_covid19/data/bronze/micro_data/ano_part=2020/mes=11/PNAD_COVID_112020.csv\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# df.toPandas().to_csv(f'{SILVER_PATH}/silver.csv')\n",
    "df.toPandas().to_parquet(f'{SILVER_PATH}/silver.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(f'{SILVER_PATH}/silver.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ano</th>\n",
       "      <th>UF</th>\n",
       "      <th>CAPITAL</th>\n",
       "      <th>RM_RIDE</th>\n",
       "      <th>V1008</th>\n",
       "      <th>V1012</th>\n",
       "      <th>V1013</th>\n",
       "      <th>V1016</th>\n",
       "      <th>Estrato</th>\n",
       "      <th>UPA</th>\n",
       "      <th>...</th>\n",
       "      <th>F0022</th>\n",
       "      <th>F002A1</th>\n",
       "      <th>F002A2</th>\n",
       "      <th>F002A3</th>\n",
       "      <th>F002A4</th>\n",
       "      <th>F002A5</th>\n",
       "      <th>F0061</th>\n",
       "      <th>F006</th>\n",
       "      <th>ano_part</th>\n",
       "      <th>mes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>None</td>\n",
       "      <td>01</td>\n",
       "      <td>4</td>\n",
       "      <td>09</td>\n",
       "      <td>5</td>\n",
       "      <td>1110011</td>\n",
       "      <td>110015970</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>None</td>\n",
       "      <td>01</td>\n",
       "      <td>4</td>\n",
       "      <td>09</td>\n",
       "      <td>5</td>\n",
       "      <td>1110011</td>\n",
       "      <td>110015970</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>None</td>\n",
       "      <td>01</td>\n",
       "      <td>4</td>\n",
       "      <td>09</td>\n",
       "      <td>5</td>\n",
       "      <td>1110011</td>\n",
       "      <td>110015970</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>None</td>\n",
       "      <td>01</td>\n",
       "      <td>4</td>\n",
       "      <td>09</td>\n",
       "      <td>5</td>\n",
       "      <td>1110011</td>\n",
       "      <td>110015970</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>None</td>\n",
       "      <td>02</td>\n",
       "      <td>1</td>\n",
       "      <td>09</td>\n",
       "      <td>5</td>\n",
       "      <td>1110011</td>\n",
       "      <td>110015970</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149192</th>\n",
       "      <td>2020</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>None</td>\n",
       "      <td>06</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>5310220</td>\n",
       "      <td>530009738</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>03</td>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149193</th>\n",
       "      <td>2020</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>None</td>\n",
       "      <td>06</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>5310220</td>\n",
       "      <td>530009738</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>03</td>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149194</th>\n",
       "      <td>2020</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>None</td>\n",
       "      <td>06</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>5310220</td>\n",
       "      <td>530009738</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>03</td>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149195</th>\n",
       "      <td>2020</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>5310220</td>\n",
       "      <td>530009738</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149196</th>\n",
       "      <td>2020</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>5310220</td>\n",
       "      <td>530009738</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1149197 rows × 147 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Ano  UF CAPITAL RM_RIDE V1008 V1012 V1013 V1016  Estrato        UPA  \\\n",
       "0        2020  11      11    None    01     4    09     5  1110011  110015970   \n",
       "1        2020  11      11    None    01     4    09     5  1110011  110015970   \n",
       "2        2020  11      11    None    01     4    09     5  1110011  110015970   \n",
       "3        2020  11      11    None    01     4    09     5  1110011  110015970   \n",
       "4        2020  11      11    None    02     1    09     5  1110011  110015970   \n",
       "...       ...  ..     ...     ...   ...   ...   ...   ...      ...        ...   \n",
       "1149192  2020  53      53    None    06     3    10     6  5310220  530009738   \n",
       "1149193  2020  53      53    None    06     3    10     6  5310220  530009738   \n",
       "1149194  2020  53      53    None    06     3    10     6  5310220  530009738   \n",
       "1149195  2020  53      53    None    10     2    10     6  5310220  530009738   \n",
       "1149196  2020  53      53    None    10     2    10     6  5310220  530009738   \n",
       "\n",
       "         ... F0022 F002A1 F002A2 F002A3 F002A4 F002A5 F0061 F006 ano_part mes  \n",
       "0        ...  None      1      1      1      2      1     1   01     2020   9  \n",
       "1        ...  None      1      1      1      2      1     1   01     2020   9  \n",
       "2        ...  None      1      1      1      2      1     1   01     2020   9  \n",
       "3        ...  None      1      1      1      2      1     1   01     2020   9  \n",
       "4        ...  None      1      1      1      2      1     1   01     2020   9  \n",
       "...      ...   ...    ...    ...    ...    ...    ...   ...  ...      ...  ..  \n",
       "1149192  ...  None      1      1      1      2      1     1   03     2020  10  \n",
       "1149193  ...  None      1      1      1      2      1     1   03     2020  10  \n",
       "1149194  ...  None      1      1      1      2      1     1   03     2020  10  \n",
       "1149195  ...  None      1      1      1      1      1     1   02     2020  10  \n",
       "1149196  ...  None      1      1      1      1      1     1   02     2020  10  \n",
       "\n",
       "[1149197 rows x 147 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
